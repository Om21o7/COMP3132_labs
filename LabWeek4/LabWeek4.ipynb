{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXQSrVGLbfCq"
      },
      "source": [
        "# Lab 4: Basic regression - Predict fuel efficiency\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9HUhbCGbfCr"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name: Om Makwana\n",
        "\n",
        "Student Id: 101414422"
      ],
      "metadata": {
        "id": "WOgVRAtBXtTR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IZf-mK3kbfCs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns # we use this library to load the dataset\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ceGRpBIbfCs"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3MF2KLxHbfCs"
      },
      "outputs": [],
      "source": [
        "# Load the 'mpg' dataset using seaborn library into a Pandas DataFrame\n",
        "df = sns.load_dataset('mpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfxdDYPNbfCs"
      },
      "source": [
        "MPG dataset can be viewed online at  \n",
        "https://github.com/mwaskom/seaborn-data/blob/master/mpg.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzRgjAwp9hYw"
      },
      "source": [
        "## Data Exploration - Pandas Review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESV9y917bfCt"
      },
      "source": [
        "### Show the first 5 rows of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iKKH1ZrrbfCt",
        "outputId": "4aa9fe05-3aaf-4f87-9151-c9375e316b71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
            "0  18.0          8         307.0       130.0    3504          12.0   \n",
            "1  15.0          8         350.0       165.0    3693          11.5   \n",
            "2  18.0          8         318.0       150.0    3436          11.0   \n",
            "3  16.0          8         304.0       150.0    3433          12.0   \n",
            "4  17.0          8         302.0       140.0    3449          10.5   \n",
            "\n",
            "   model_year origin                       name  \n",
            "0          70    usa  chevrolet chevelle malibu  \n",
            "1          70    usa          buick skylark 320  \n",
            "2          70    usa         plymouth satellite  \n",
            "3          70    usa              amc rebel sst  \n",
            "4          70    usa                ford torino  \n"
          ]
        }
      ],
      "source": [
        "#your code here\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5UukwBAdgXb"
      },
      "source": [
        "### Show the size of the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1hfYc4Zdd1iL",
        "outputId": "de81ce9a-49c1-434d-8bea-1667d2e2dc07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(398, 9)\n"
          ]
        }
      ],
      "source": [
        "print(df.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4UwwzRrd9WY"
      },
      "source": [
        "### Find the columns name and their types (numerical or categorical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TSNv_Siqd3xl",
        "outputId": "6f30ff14-3bdb-47f5-90a3-a6e62baf5cbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mpg             float64\n",
            "cylinders         int64\n",
            "displacement    float64\n",
            "horsepower      float64\n",
            "weight            int64\n",
            "acceleration    float64\n",
            "model_year        int64\n",
            "origin           object\n",
            "name             object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df.dtypes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heVHvJgZhc53"
      },
      "source": [
        "### Find the number of missing values in each column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "imTo-ss8hy48",
        "outputId": "c021eb50-3614-481b-f681-8be693f5b270",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mpg             0\n",
            "cylinders       0\n",
            "displacement    0\n",
            "horsepower      6\n",
            "weight          0\n",
            "acceleration    0\n",
            "model_year      0\n",
            "origin          0\n",
            "name            0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJyFFJi_j186"
      },
      "source": [
        "### Handle the missing values in the dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "695skg69ikSP"
      },
      "source": [
        "Since the number of missing values is low, we can simply drop the rows containing them. However, as a practice and review, let's substitute the missing values in the numerical columns (if any) with the mean of the respective column and the missing values in the categorical columns (if any) with the median of the respective column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aE2UQsu0j843"
      },
      "outputs": [],
      "source": [
        "\n",
        "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
        "df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].mean())\n",
        "\n",
        "categorical_columns = df.select_dtypes(exclude=[np.number]).columns\n",
        "df[categorical_columns] = df[categorical_columns].fillna(df[categorical_columns].mode().iloc[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXeUz8BArqXK"
      },
      "source": [
        "### Compute the average and the median weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VuzHC1werwiv",
        "outputId": "2c67743b-56f1-4071-a05c-7cbc833a7832",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average weight: 2970.42\n",
            "Median weight: 2803.50\n"
          ]
        }
      ],
      "source": [
        "average_weight = df['weight'].mean()\n",
        "median_weight = df['weight'].median()\n",
        "print(f\"Average weight: {average_weight:.2f}\")\n",
        "print(f\"Median weight: {median_weight:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb5hLSIYsZE1"
      },
      "source": [
        "### Find the number of cars that weight more than 2000 kgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eDfsiR1Ysf0q",
        "outputId": "f081fdaf-dfe4-4e71-9045-0c5f01be3f23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of cars weighing more than 2000 kg: 354\n"
          ]
        }
      ],
      "source": [
        "cars_over_2000kg = df[df['weight'] > 2000].shape[0]\n",
        "print(f\"Number of cars weighing more than 2000 kg: {cars_over_2000kg}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3nE8VBksl20"
      },
      "source": [
        "### Find how many cars there are for each number of cylinders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-865t6xpsy4c",
        "outputId": "171c4817-46ca-4854-94c3-d90d72c222ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cylinders\n",
            "4    204\n",
            "8    103\n",
            "6     84\n",
            "3      4\n",
            "5      3\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "cylinder_counts = df['cylinders'].value_counts()\n",
        "print(cylinder_counts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4ofBIrVtQRS"
      },
      "source": [
        "### Find what are the car models with number of cylinders (3 or 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CtKqSLQxtOOb",
        "outputId": "be2ab536-718d-4db3-ffb8-1b5f1de7f664",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    name  cylinders\n",
            "71       mazda rx2 coupe          3\n",
            "111            maxda rx3          3\n",
            "243           mazda rx-4          3\n",
            "274            audi 5000          5\n",
            "297   mercedes benz 300d          5\n",
            "327  audi 5000s (diesel)          5\n",
            "334        mazda rx-7 gs          3\n"
          ]
        }
      ],
      "source": [
        "cars_3_5_cylinders = df[df['cylinders'].isin([3, 5])]\n",
        "print(cars_3_5_cylinders[['name', 'cylinders']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35WxtvxtU-X_"
      },
      "source": [
        "### Show the `value_counts()` of `origin` column or show the unique values of this column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "UoQRTFJBU-tF",
        "outputId": "6a9cd6f7-61b9-4367-83ce-55f6e51620f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "origin\n",
            "usa       249\n",
            "japan      79\n",
            "europe     70\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df['origin'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGRxYTsrXLJf"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzIQgkXiVYBX"
      },
      "source": [
        "### Use one hot encoding to change the categorical values of `origin` column to numerical values.\n",
        "\n",
        "- use `pd.get_dummies()` method to do the encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GfueZMVGUrOO"
      },
      "outputs": [],
      "source": [
        "df = pd.get_dummies(df, columns=['origin'], prefix='origin')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtLp74JWXPp6"
      },
      "source": [
        "### Remove the name column form the dataframe to have all numerical dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "V1A0DsEVXgXm"
      },
      "outputs": [],
      "source": [
        "df = df.drop('name', axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuJ1dAYdY8JM"
      },
      "source": [
        "### Does the input needs reshaping?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "F68KMJTztVzS"
      },
      "outputs": [],
      "source": [
        "# The input doesn't need reshaping at this point because we're working with a 2D dataset (rows of features)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDwS5PqJaqb7"
      },
      "source": [
        "### Split the data into training and test sets and form `train_features`, `train_labels`, `test_features`, `test_labels`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "SZPxsIJcapzq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separate features and labels\n",
        "X = df.drop('mpg', axis=1)\n",
        "y = df['mpg']\n",
        "\n",
        "# Split the data\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePcXIunjxLGW"
      },
      "source": [
        "### For simplicity in the following steps, convert the dataset from a pandas DataFrame to a numpy array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "zHAfvRbkxfeH"
      },
      "outputs": [],
      "source": [
        "train_features = np.array(train_features)\n",
        "train_labels = np.array(train_labels)\n",
        "test_features = np.array(test_features)\n",
        "test_labels = np.array(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = train_features.astype(float)\n",
        "test_features = test_features.astype(float)\n"
      ],
      "metadata": {
        "id": "2SxfUZEZWVZN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCfztMDkyeLX"
      },
      "source": [
        "## Normalization layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWPepaJ20buG"
      },
      "source": [
        "To ensure stable training of neural networks, we typically normalize the data. This process also enhances the convergence of the gradient descent algorithm.\n",
        "\n",
        "There is not single way to normalize the data. You can also use `scikit-learn `or `pandas` to do it. However, in this lab, we will use the normalization layer provided by tensorflow which matches the other parts of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfuJRF3syqJL"
      },
      "source": [
        "The `tf.keras.layers.Normalization` is a clean and simple way to add feature normalization into your model.\n",
        "\n",
        "The first step is to create the layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GAOoajCuyiAa"
      },
      "outputs": [],
      "source": [
        "normalizer = tf.keras.layers.Normalization(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsvUWg8dy8TA"
      },
      "source": [
        "Then, fit the state of the preprocessing layer to the data by calling `Normalization.adapt`.\n",
        "\n",
        "It calculates the mean and variance of each feature, and store them in the layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ozpNzkLJzHe2"
      },
      "outputs": [],
      "source": [
        "normalizer.adapt(train_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQqwlS4HzXeM"
      },
      "source": [
        "When the layer is called, it returns the input data, with each feature independently normalized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXHLcbqWzdmN",
        "outputId": "a8592e40-61d8-4524-f5da-d57ff6ce57e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First example: [8.000e+00 3.040e+02 1.500e+02 3.433e+03 1.200e+01 7.000e+01 0.000e+00\n",
            " 0.000e+00 1.000e+00]\n",
            "\n",
            "Normalized: [[ 1.5271883   1.0901965   1.2618345   0.55282634 -1.3193338  -1.6966677\n",
            "  -0.46232074 -0.5117663   0.7889544 ]]\n"
          ]
        }
      ],
      "source": [
        "first = train_features[0]\n",
        "print('First example:', first)\n",
        "print()\n",
        "print('Normalized:', normalizer(first).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8u33n29vmFJ"
      },
      "source": [
        "## **Approach #1:** Regression using `Linear Regression`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6anRxth1MXq"
      },
      "source": [
        "**You are welcome to use scikit-learn to perform linear regression on this dataset.**\n",
        "\n",
        "However, here we aim to implement it using TensorFlow.\n",
        "\n",
        "- As we saw in Lab Week 2, `logistic regression` is essentially a single neuron with a `sigmoid` activation function.\n",
        "\n",
        "- Similarly, `linear regression` can be viewed as a single neuron with a `linear` activation function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbWqUxQa2jjY"
      },
      "source": [
        "### **Step 1:** Linear regression model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "YG9lzGcf2H9o"
      },
      "outputs": [],
      "source": [
        "linear_model = tf.keras.Sequential([\n",
        "    normalizer,\n",
        "    layers.Dense(1, activation='linear')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idRd4rDjUrOQ"
      },
      "source": [
        "**Note:** You can define your model all at once like the cell above or you can buid the model incrementaly  (suitable for your assignment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1jiSE267UrOQ"
      },
      "outputs": [],
      "source": [
        "# Defining the model incrementaly (suitable for your assignment)\n",
        "linear_model = tf.keras.Sequential()\n",
        "linear_model.add(normalizer)\n",
        "linear_model.add(layers.Dense(1, activation='linear'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpCRMAeW2o0-"
      },
      "source": [
        "### **Step 2:** Configure the model with Keras `Model.compile()`\n",
        "\n",
        "The most important arguments to compile are the `loss` and the `optimizer`, since these define what will be optimized (`\"mean_absolute_error\"`) and how (using the `tf.keras.optimizers.Adam(learning_rate=0.1)`).\n",
        "\n",
        "**arguments:**\n",
        "- optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
        "- loss='mean_absolute_error'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "aun9zdxH9Mtq"
      },
      "outputs": [],
      "source": [
        "linear_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
        "    loss='mean_absolute_error'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAwyyRjF4cfv"
      },
      "source": [
        "### **Step 3:** Train the model using the `Model.fit()` for `100` epochs, and store the output in a variable named history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbcTeooJ4cxr",
        "outputId": "d6927d52-ddce-474d-893a-35aa455aa6b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 23.3290\n",
            "Epoch 2/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 22.5871  \n",
            "Epoch 3/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.3664 \n",
            "Epoch 4/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.6509 \n",
            "Epoch 5/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.6695 \n",
            "Epoch 6/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18.1616 \n",
            "Epoch 7/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17.2716 \n",
            "Epoch 8/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16.2431 \n",
            "Epoch 9/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16.1125 \n",
            "Epoch 10/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.8266 \n",
            "Epoch 11/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.6455 \n",
            "Epoch 12/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.0434 \n",
            "Epoch 13/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.6760\n",
            "Epoch 14/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.0743\n",
            "Epoch 15/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.3087  \n",
            "Epoch 16/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.3525 \n",
            "Epoch 17/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.1021 \n",
            "Epoch 18/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.5662 \n",
            "Epoch 19/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3464 \n",
            "Epoch 20/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8880 \n",
            "Epoch 21/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2044 \n",
            "Epoch 22/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7330 \n",
            "Epoch 23/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1554 \n",
            "Epoch 24/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7476 \n",
            "Epoch 25/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6421 \n",
            "Epoch 26/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7311 \n",
            "Epoch 27/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7299 \n",
            "Epoch 28/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5219 \n",
            "Epoch 29/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4476 \n",
            "Epoch 30/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5506 \n",
            "Epoch 31/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5996 \n",
            "Epoch 32/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5070 \n",
            "Epoch 33/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5512 \n",
            "Epoch 34/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7196 \n",
            "Epoch 35/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6249 \n",
            "Epoch 36/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5525 \n",
            "Epoch 37/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3949 \n",
            "Epoch 38/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5672 \n",
            "Epoch 39/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5414 \n",
            "Epoch 40/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4989 \n",
            "Epoch 41/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4674 \n",
            "Epoch 42/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7835 \n",
            "Epoch 43/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5861 \n",
            "Epoch 44/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3737 \n",
            "Epoch 45/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6627 \n",
            "Epoch 46/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5306 \n",
            "Epoch 47/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5931 \n",
            "Epoch 48/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5549 \n",
            "Epoch 49/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4046 \n",
            "Epoch 50/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5492 \n",
            "Epoch 51/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5249 \n",
            "Epoch 52/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7640 \n",
            "Epoch 53/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6597 \n",
            "Epoch 54/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5490 \n",
            "Epoch 55/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4806 \n",
            "Epoch 56/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5075 \n",
            "Epoch 57/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5291 \n",
            "Epoch 58/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4437 \n",
            "Epoch 59/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6834  \n",
            "Epoch 60/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3953  \n",
            "Epoch 61/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4940 \n",
            "Epoch 62/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4810 \n",
            "Epoch 63/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6071 \n",
            "Epoch 64/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5201 \n",
            "Epoch 65/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5872 \n",
            "Epoch 66/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4621  \n",
            "Epoch 67/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6002 \n",
            "Epoch 68/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6398 \n",
            "Epoch 69/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4865 \n",
            "Epoch 70/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6205 \n",
            "Epoch 71/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3897 \n",
            "Epoch 72/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3623 \n",
            "Epoch 73/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5529 \n",
            "Epoch 74/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5235 \n",
            "Epoch 75/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6759 \n",
            "Epoch 76/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5617 \n",
            "Epoch 77/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6852 \n",
            "Epoch 78/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6462 \n",
            "Epoch 79/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6692 \n",
            "Epoch 80/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5778 \n",
            "Epoch 81/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5664 \n",
            "Epoch 82/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5894 \n",
            "Epoch 83/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3113 \n",
            "Epoch 84/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5871 \n",
            "Epoch 85/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9874 \n",
            "Epoch 86/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7753 \n",
            "Epoch 87/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5155 \n",
            "Epoch 88/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4697 \n",
            "Epoch 89/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6063 \n",
            "Epoch 90/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5000 \n",
            "Epoch 91/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4601 \n",
            "Epoch 92/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6512 \n",
            "Epoch 93/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4893 \n",
            "Epoch 94/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.4893 \n",
            "Epoch 95/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3698 \n",
            "Epoch 96/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5565 \n",
            "Epoch 97/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4354 \n",
            "Epoch 98/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.4465 \n",
            "Epoch 99/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4929 \n",
            "Epoch 100/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7128 \n"
          ]
        }
      ],
      "source": [
        "history = linear_model.fit(train_features, train_labels, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoSWSu4peUmG",
        "outputId": "1f81eb9a-a1f4-4023-b9e4-32991929a572"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [23.222951889038086,\n",
              "  22.171266555786133,\n",
              "  21.181859970092773,\n",
              "  20.18698501586914,\n",
              "  19.178621292114258,\n",
              "  18.19468879699707,\n",
              "  17.17322540283203,\n",
              "  16.186227798461914,\n",
              "  15.198724746704102,\n",
              "  14.18228816986084,\n",
              "  13.20175838470459,\n",
              "  12.206404685974121,\n",
              "  11.221220970153809,\n",
              "  10.219620704650879,\n",
              "  9.215703010559082,\n",
              "  8.23814868927002,\n",
              "  7.289544105529785,\n",
              "  6.356845855712891,\n",
              "  5.491885185241699,\n",
              "  4.699347972869873,\n",
              "  4.024704456329346,\n",
              "  3.5460946559906006,\n",
              "  3.1875717639923096,\n",
              "  2.946077585220337,\n",
              "  2.762986183166504,\n",
              "  2.694800615310669,\n",
              "  2.667499542236328,\n",
              "  2.621479034423828,\n",
              "  2.5905773639678955,\n",
              "  2.5802557468414307,\n",
              "  2.5812923908233643,\n",
              "  2.571078300476074,\n",
              "  2.6049623489379883,\n",
              "  2.613426446914673,\n",
              "  2.586092948913574,\n",
              "  2.5598745346069336,\n",
              "  2.5614445209503174,\n",
              "  2.55812931060791,\n",
              "  2.5577564239501953,\n",
              "  2.5716030597686768,\n",
              "  2.586482286453247,\n",
              "  2.563241720199585,\n",
              "  2.5636661052703857,\n",
              "  2.5514817237854004,\n",
              "  2.546396017074585,\n",
              "  2.568166732788086,\n",
              "  2.5784878730773926,\n",
              "  2.549414873123169,\n",
              "  2.5422871112823486,\n",
              "  2.555546283721924,\n",
              "  2.5773305892944336,\n",
              "  2.5707147121429443,\n",
              "  2.5383965969085693,\n",
              "  2.5722451210021973,\n",
              "  2.551609754562378,\n",
              "  2.5447816848754883,\n",
              "  2.5486671924591064,\n",
              "  2.5698554515838623,\n",
              "  2.6141068935394287,\n",
              "  2.5800673961639404,\n",
              "  2.581960916519165,\n",
              "  2.5605967044830322,\n",
              "  2.552090644836426,\n",
              "  2.546219825744629,\n",
              "  2.5456583499908447,\n",
              "  2.54642653465271,\n",
              "  2.572800636291504,\n",
              "  2.5419907569885254,\n",
              "  2.5508065223693848,\n",
              "  2.565263509750366,\n",
              "  2.551532506942749,\n",
              "  2.559483051300049,\n",
              "  2.55838942527771,\n",
              "  2.5560739040374756,\n",
              "  2.57419753074646,\n",
              "  2.5491108894348145,\n",
              "  2.558098077774048,\n",
              "  2.5384156703948975,\n",
              "  2.5691943168640137,\n",
              "  2.574317693710327,\n",
              "  2.5459601879119873,\n",
              "  2.5458872318267822,\n",
              "  2.5621728897094727,\n",
              "  2.564772605895996,\n",
              "  2.589618444442749,\n",
              "  2.550917148590088,\n",
              "  2.5711772441864014,\n",
              "  2.549520492553711,\n",
              "  2.5708892345428467,\n",
              "  2.5453412532806396,\n",
              "  2.554689884185791,\n",
              "  2.546863079071045,\n",
              "  2.544541120529175,\n",
              "  2.552830457687378,\n",
              "  2.5621018409729004,\n",
              "  2.5479180812835693,\n",
              "  2.566330671310425,\n",
              "  2.602489471435547,\n",
              "  2.6165218353271484,\n",
              "  2.5851516723632812]}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "history.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "MMO4NC-05bON",
        "outputId": "8aef3b78-a352-4c85-cdbe-2b36c372c0e9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Error [MPG]')\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "\n",
        "plot_loss(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGft7eZOUrOR"
      },
      "source": [
        "### Get the model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "5FPKx-bbUrOR",
        "outputId": "15299ca4-9bdf-4a93-8459-97599ed42d11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ normalization (\u001b[38;5;33mNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │              \u001b[38;5;34m19\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m10\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ normalization (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m51\u001b[0m (212.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> (212.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10\u001b[0m (40.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> (40.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m19\u001b[0m (80.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19</span> (80.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m22\u001b[0m (92.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22</span> (92.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "linear_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASE-T2jk6cAN"
      },
      "source": [
        "### **Step 4:** Evaluate the linear model on the test set using Keras `Model.evaluate()` and see the `mean_absolute_error` and save the result for future comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "FgB74EEj9GRJ",
        "outputId": "ef82dfc1-d8f4-4de9-c94a-1e25f77723f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Model - Test Mean Absolute Error: 2.1562\n"
          ]
        }
      ],
      "source": [
        "linear_model_results = linear_model.evaluate(test_features, test_labels, verbose=0)\n",
        "print(f\"Linear Model - Test Mean Absolute Error: {linear_model_results:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWfd69aOXkQD"
      },
      "source": [
        "## **Approach #2:** Regression using a `Deep Neural Network (DNN)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P1NT4XmYgxv"
      },
      "source": [
        "### Solve the same problem and using deep neural network with the sample architecture;\n",
        "- 1st hidden layer no. of units =  64\n",
        "- 2nd hidden layer no. of units = 64\n",
        "- Choose appropriate `activation` functions for hidden and output layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "HDREKddrYdr5",
        "outputId": "5f0e617e-408f-402a-f40a-b257bd0aca32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ normalization (\u001b[38;5;33mNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │              \u001b[38;5;34m19\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m640\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ normalization (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,616\u001b[0m (57.10 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,616</span> (57.10 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,865\u001b[0m (19.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,865</span> (19.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m19\u001b[0m (80.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19</span> (80.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m9,732\u001b[0m (38.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,732</span> (38.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNN Model - Test Mean Absolute Error: 2.1859\n"
          ]
        }
      ],
      "source": [
        "dnn_model = tf.keras.Sequential([\n",
        "    normalizer,\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "dnn_model.compile(optimizer=tf.keras.optimizers.Adam(0.1), loss='mean_absolute_error')\n",
        "dnn_model.fit(train_features, train_labels, epochs=100, verbose=0)\n",
        "\n",
        "dnn_model.summary()\n",
        "\n",
        "\n",
        "dnn_model_results = dnn_model.evaluate(test_features, test_labels, verbose=0)\n",
        "print(f\"DNN Model - Test Mean Absolute Error: {dnn_model_results:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR9zUjbGUrOR"
      },
      "source": [
        "### Print the model summary (after training). How many parameters are there in the model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "JIuvPWoaUrOR",
        "outputId": "67cccbf4-ee71-4473-980f-8c042cd02c38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ normalization (\u001b[38;5;33mNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │              \u001b[38;5;34m19\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m640\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ normalization (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,616\u001b[0m (57.10 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,616</span> (57.10 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,865\u001b[0m (19.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,865</span> (19.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m19\u001b[0m (80.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19</span> (80.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m9,732\u001b[0m (38.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,732</span> (38.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "dnn_model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouZJ8wvOUrOR"
      },
      "source": [
        "### You can see even this small model has more than 4000 trainable parameters. The more the number of parameters, the longer the training time and cost. Search the net and see how many trainable parameters does the `ChatGPT` model have? What about `DeepSeek` model? (Optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChatGPT and DeepSeek models have significantly more parameters than the small model with 4,000 trainable parameters:\n",
        "ChatGPT (GPT-4) is estimated to have approximately 1.8 trillion parameters7. This is orders of magnitude larger than the small model discussed earlier.\n",
        "DeepSeek has multiple models with varying parameter counts:\n",
        "DeepSeek V3 is a Mixture of Experts (MoE) model with 671 billion total parameters. However, it uses only 37 billion parameters per token during inference, making it more computationally efficient48.\n",
        "DeepSeek-R1, an earlier model, likely has fewer parameters than V3, but the exact count is not specified in the search results.\n",
        "These large language models require substantial computational resources and time to train. For example, DeepSeek V3 was reportedly trained with a budget of approximately $6 million8. The massive number of parameters in these models contributes to their ability to perform complex language tasks but also increases the challenges of training and deployment."
      ],
      "metadata": {
        "id": "tC0rt5cYXHse"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX-BabwxGI6B"
      },
      "source": [
        "## Compare the evaluation result of the two approaches, i.e., linear regression and deep neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison: Linear Regression vs Deep Neural Network\n",
        "Performance Metrics\n",
        "Accuracy: Deep Neural Networks (DNN) typically outperform linear regression\n",
        "Complexity: DNN can capture non-linear relationships\n",
        "Interpretability: Linear regression is more transparent\n",
        "Computational Requirements:\n",
        "Linear Regression: Low computational cost\n",
        "DNN: High computational cost, requires more resources\n",
        "Key Differences\n",
        "Linear regression best for simple, linear relationships\n",
        "Neural networks excel with complex, non-linear data\n",
        "Neural networks require more data and training time\n",
        "Linear regression provides easier model interpretation\n"
      ],
      "metadata": {
        "id": "RZlC2udrXaXR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxpdQIsvUrOS"
      },
      "source": [
        "## Use the following large model and evaluate it on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Z9fKwgjrUrOS"
      },
      "outputs": [],
      "source": [
        "model_dnn_large = tf.keras.Sequential([\n",
        "    normalizer,\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='linear')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dnn_large.compile(optimizer=tf.keras.optimizers.Adam(0.1), loss='mean_absolute_error')\n",
        "model_dnn_large.fit(train_features, train_labels, epochs=100, verbose=0)\n",
        "\n",
        "large_model_results = model_dnn_large.evaluate(test_features, test_labels, verbose=0)\n",
        "print(f\"Large DNN Model - Test Mean Absolute Error: {large_model_results:.4f}\")"
      ],
      "metadata": {
        "id": "ejSEKtHyXffZ",
        "outputId": "acefd893-8599-42f8-8ecd-6d629e25c4f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Large DNN Model - Test Mean Absolute Error: 2.0201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60SLF8lYUrOS"
      },
      "source": [
        "### Explain your observation. Why do you think the large model is not performing well?\n",
        "\n",
        "- hint: when the number of trainable parameters is very large (even larger than the number of data points), the model may overfit the training data.One way to solve this problem is to use more data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation: Large Model Underperformance\n",
        "The large model with multiple hidden layers is likely not performing well due to overfitting. Here's a concise explanation:\n",
        "Reasons for Poor Performance\n",
        "Overfitting: Too many parameters relative to the dataset size.\n",
        "Limited Data: The MPG dataset is relatively small.\n",
        "Model Complexity: The model's capacity exceeds the problem's complexity.\n",
        "Explanation\n",
        "When the number of trainable parameters significantly exceeds the number of data points:\n",
        "The model memorizes training data instead of learning generalizable patterns.\n",
        "It performs well on training data but poorly on unseen test data.\n",
        "Solutions\n",
        "Increase Dataset Size: More data helps the model generalize better.\n",
        "Reduce Model Complexity: Use fewer layers or neurons.\n",
        "Apply Regularization: Techniques like dropout or L2 regularization.\n",
        "Early Stopping: Halt training when validation performance degrades.\n",
        "Cross-Validation: For more robust performance estimation."
      ],
      "metadata": {
        "id": "4S9R663TXnac"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPnoN9zyUrOS"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}